{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a GCN with neighbor sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import dgl.nn\n",
    "import dgl.dataloading\n",
    "import dgl.sampling\n",
    "import dgl.function as fn\n",
    "import ogb.nodeproppred\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "dataset = ogb.nodeproppred.DglNodePropPredDataset('ogbn-products')\n",
    "g, labels = dataset[0]\n",
    "labels = labels[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spl = dataset.get_idx_split()\n",
    "train_idx = spl['train']\n",
    "val_idx = spl['valid']\n",
    "test_idx = spl['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The message passing formulation is\n",
    "\n",
    "$$\n",
    "h_{v}^{(l+1)} = \\sigma \\left( \\sum_{u \\in \\mathcal{N}(v)} e_{uv} h_{u}^{(l)} W^{(l+1)} \\right)\n",
    "$$\n",
    "\n",
    "where $e_{uv} = \\dfrac{1}{\\sqrt{d_u d_v}}$ is the entry of the graph Laplacian on $u$-th row and $v$-th column.\n",
    "\n",
    "We estimate it via neighbor sampling with\n",
    "\n",
    "$$\n",
    "\\tilde{h}_{v}^{(l+1)} = \\sigma \\left( \\tilde{D}_v \\mathbb{E}_{u \\sim P_v(u)}  \\left[ \\tilde{h}_{u}^{(l)} W^{(l+1)} \\right] \\right)\n",
    "$$\n",
    "\n",
    "where $P_v(u) \\propto e_{uv}$ and $\\tilde{D}_v = \\sum_{u \\in \\mathcal{N}(v)} e_{uv}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute $e$ and $\\tilde{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_D_and_e(g):\n",
    "    g.ndata['D_in'] = 1 / g.in_degrees().float().sqrt()\n",
    "    g.ndata['D_out'] = 1 / g.out_degrees().float().sqrt()\n",
    "    g.apply_edges(fn.u_mul_v('D_in', 'D_out', 'e'))\n",
    "    g.update_all(fn.copy_e('e', 'm'), fn.sum('m', 'D_tilde'))\n",
    "    g.edata['e'] = g.edata['e'].view(g.num_edges(), 1)\n",
    "    # produces g.edata['e'] and g.ndata['D_tilde']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.add_self_loop(dgl.remove_self_loop(g))\n",
    "compute_D_and_e(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_dims, out_dims):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = nn.Linear(in_dims, out_dims)\n",
    "        \n",
    "    def forward_train(self, block, x):\n",
    "        with block.local_scope():\n",
    "            block.srcdata['x'] = x\n",
    "            block.update_all(fn.copy_u('x', 'm'), fn.mean('m', 'y'))\n",
    "            y = block.dstdata['y']\n",
    "            return self.W(y) * block.dstdata['D_tilde'][:, None]   # D_tilde is computed outside in preprocessing stage\n",
    "        \n",
    "    def forward_eval(self, block, x):\n",
    "        with block.local_scope():\n",
    "            block.srcdata['x'] = x\n",
    "            block.update_all(fn.u_mul_e('x', 'e', 'm'), fn.sum('m', 'y'))\n",
    "            return self.W(block.dstdata['y'])\n",
    "        \n",
    "    def forward(self, block, x):\n",
    "        if self.training:\n",
    "            return self.forward_train(block, x)\n",
    "        else:\n",
    "            return self.forward_eval(block, x)\n",
    "\n",
    "class StochasticGCN(nn.Module):\n",
    "    def __init__(self, in_dims, hid_dims, out_dims):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = Conv(in_dims, hid_dims)\n",
    "        self.conv2 = Conv(hid_dims, hid_dims)\n",
    "        self.conv3 = Conv(hid_dims, out_dims)\n",
    "        \n",
    "        self.hid_dims = hid_dims\n",
    "        self.out_dims = out_dims\n",
    "        \n",
    "    def forward(self, blocks, x):\n",
    "        x = F.relu(self.conv1(blocks[0], x))\n",
    "        x = F.relu(self.conv2(blocks[1], x))\n",
    "        x = self.conv3(blocks[2], x)\n",
    "        return x\n",
    "    \n",
    "    def inference(self, g, x, batch_size, device):\n",
    "        layers = [self.conv1, self.conv2, self.conv3]\n",
    "        \n",
    "        for l, layer in enumerate(layers):\n",
    "            y = torch.zeros(g.num_nodes(), self.hid_dims if l != len(layers) - 1 else self.out_dims)\n",
    "            \n",
    "            sampler = dgl.dataloading.MultiLayerFullNeighborSampler(1)\n",
    "            dataloader = dgl.dataloading.NodeDataLoader(\n",
    "                g,\n",
    "                torch.arange(g.num_nodes()),\n",
    "                sampler,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                drop_last=False,\n",
    "                num_workers=4)\n",
    "            \n",
    "            for input_nodes, output_nodes, blocks in tqdm.tqdm(dataloader):\n",
    "                block = blocks[0].to(device)\n",
    "                \n",
    "                # get inputs\n",
    "                h = x[input_nodes].to(device)\n",
    "                \n",
    "                # This must match the procedure in forward()\n",
    "                h = layer(block, h)\n",
    "                if l != len(layers) - 1:\n",
    "                    h = F.relu(h)\n",
    "                    \n",
    "                # write outputs\n",
    "                y[output_nodes] = h.cpu()\n",
    "                \n",
    "            x = y\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonUniformNeighborSampler(dgl.dataloading.MultiLayerNeighborSampler):\n",
    "    def __init__(self, fanouts, return_eids=False):\n",
    "        # Always with replacement\n",
    "        super().__init__(fanouts, replace=True, return_eids=return_eids)\n",
    "        \n",
    "    def sample_frontier(self, block_id, g, seed_nodes):\n",
    "        fanout = self.fanouts[block_id]\n",
    "        # e refers to the weights on each edge (i.e. graph Laplacian).\n",
    "        frontier = dgl.sampling.sample_neighbors(g, seed_nodes, fanout, replace=True, prob='e')\n",
    "        return frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "\n",
    "sampler = NonUniformNeighborSampler([5, 10, 15])\n",
    "dataloader = dgl.dataloading.NodeDataLoader(\n",
    "    g, train_idx, sampler, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(pred, labels):\n",
    "    return ((torch.argmax(pred, dim=1) == labels).float().sum() / len(pred)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "N_EPOCHS = 20\n",
    "LR = 0.003\n",
    "\n",
    "model = StochasticGCN(g.ndata['feat'].shape[1], 256, dataset.num_classes).cuda()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [01:56<00:00,  1.66it/s, loss=1.065, acc=0.857]\n",
      "100%|██████████| 2392/2392 [01:15<00:00, 31.56it/s]\n",
      "100%|██████████| 2392/2392 [01:39<00:00, 23.96it/s]\n",
      "100%|██████████| 2392/2392 [01:30<00:00, 26.38it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc 0.8800193071365356 Test Acc 0.7254767417907715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 127/193 [01:16<00:38,  1.73it/s, loss=0.525, acc=0.889]"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    with tqdm.tqdm(dataloader) as tq:\n",
    "        for step, (input_nodes, seeds, blocks) in enumerate(tq):\n",
    "            blocks = [block.to('cuda') for block in blocks]\n",
    "            batch_inputs = blocks[0].srcdata['feat']\n",
    "            batch_labels = labels[seeds].cuda()\n",
    "\n",
    "            batch_pred = model(blocks, batch_inputs)\n",
    "            loss = F.cross_entropy(batch_pred, batch_labels)\n",
    "            acc = compute_acc(batch_pred, batch_labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            tq.set_postfix({'loss': '%.3f' % loss.item(), 'acc': '%.3f' % acc}, refresh=False)\n",
    "            \n",
    "        if epoch % 5 == 0:\n",
    "            # evaluate every 5 epochs\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model.inference(g, g.ndata['feat'], BATCH_SIZE, 'cuda')\n",
    "            model.train()\n",
    "            \n",
    "            val_acc = compute_acc(pred[val_idx], labels[val_idx])\n",
    "            test_acc = compute_acc(pred[test_idx], labels[test_idx])\n",
    "            \n",
    "            print('Val Acc', val_acc, 'Test Acc', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
